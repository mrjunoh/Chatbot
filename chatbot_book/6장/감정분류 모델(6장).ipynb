{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 읽어오기- 1\n",
    "train_file = './Chatbot_data/ChatbotData.csv'\n",
    "data = pd.read_csv(train_file, delimiter=',')\n",
    "features = data['Q'].tolist()\n",
    "labels = data['label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 인덱스 시퀀스 벡터 - 2\n",
    "corpus = [preprocessing.text.text_to_word_sequence(text) for text in features]\n",
    "tokenizer = preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "sequences = tokenizer.texts_to_sequences(corpus)\n",
    "#text_to_word_sequence를 이용해 단어 시퀀스를 만든 후 corpus에 저장\n",
    "#다음 텐서플로 토크나이저의 texts_to_sequences를 이용해 문장 내 모든 단어를 시퀀스 번호로 변환한다.\n",
    "#단어 시퀀스 벡터 크기를 맞추기 위해 밑에 있는 padded_seqs를 이용해 패딩 처리함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 15 #단어 시퀀스 벡터 크기 - 3\n",
    "padded_seqs = preprocessing.sequence.pad_sequences(sequences, maxlen=MAX_SEQ_LEN, padding='post')\n",
    "\n",
    "#벡터 크기가 재각각이여서 학습시키려면 같게 만들어줘야함\n",
    "# max_seq_len을 이용해 벡터 크기 맞춤\n",
    "# 크기가 작은 단어는 공간이 남는데 그 부분을 0으로 채워준다.\n",
    "# 이 과정을 패딩 padding이라 한다. \n",
    "# 케라스에서 pad_sequences() 함수를 통해 시퀀스의 패딩 처리를 손쉽게 할 수 있다.\n",
    "# maxlen 인자로 시퀀스의 최대 길이를 정하는데 학습시킬 문장 데이터들을 사전에 분석해 파악해야한다.\n",
    "# 너무 크면 자원 낭비, 작게 잡으면 데이터 손실이 발생"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트용 데이터셋 생성 - 4\n",
    "ds = tf.data.Dataset.from_tensor_slices((padded_seqs, labels))\n",
    "ds = ds.shuffle(len(features))\n",
    "test_ds = ds.take(2000).batch(20) # 테스트 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 15)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 15, 128)      1715072     ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 15, 128)      0           ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 13, 128)      49280       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 12, 128)      65664       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 11, 128)      82048       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " global_max_pooling1d (GlobalMa  (None, 128)         0           ['conv1d[0][0]']                 \n",
      " xPooling1D)                                                                                      \n",
      "                                                                                                  \n",
      " global_max_pooling1d_1 (Global  (None, 128)         0           ['conv1d_1[0][0]']               \n",
      " MaxPooling1D)                                                                                    \n",
      "                                                                                                  \n",
      " global_max_pooling1d_2 (Global  (None, 128)         0           ['conv1d_2[0][0]']               \n",
      " MaxPooling1D)                                                                                    \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 384)          0           ['global_max_pooling1d[0][0]',   \n",
      "                                                                  'global_max_pooling1d_1[0][0]', \n",
      "                                                                  'global_max_pooling1d_2[0][0]'] \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          49280       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 128)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " logits (Dense)                 (None, 3)            387         ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 3)            12          ['logits[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,961,743\n",
      "Trainable params: 1,961,743\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "100/100 - 0s - loss: 0.0734 - accuracy: 0.9770 - 432ms/epoch - 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07340554147958755, 0.9769999980926514]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CNN 모델 불러오기\n",
    "model = load_model('cnn_model.h5')\n",
    "model.summary()\n",
    "model.evaluate(test_ds, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 시퀀스 :  ['썸', '타는', '여자가', '남사친', '만나러', '간다는데', '뭐라', '해']\n",
      "단어 인덱스 시퀀스 :  [   13    61   127  4320  1333 12162   856    31     0     0     0     0\n",
      "     0     0     0]\n",
      "문장 분류(정답) :  2\n"
     ]
    }
   ],
   "source": [
    "# 테스트용 데이터셋의 10212번째 데이터 출력 -5 \n",
    "print('단어 시퀀스 : ', corpus[10212])\n",
    "print('단어 인덱스 시퀀스 : ', padded_seqs[10212])\n",
    "print('문장 분류(정답) : ', labels[10212])\n",
    "\n",
    "#10212번째 문장의 단어 시퀀스와 시퀀스 번호 그리고 해당 문장의 감정 클래스 정답을 출력한 결과\n",
    "#10212번째 문장은 사랑(label:2)으로 분류된 문장이다.\n",
    "#실제 값\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 128ms/step\n",
      "감정 예측 점수 :  [[9.1608985e-07 1.8638556e-06 9.9999726e-01]]\n",
      "감정 예측 클래스 :  [2]\n"
     ]
    }
   ],
   "source": [
    "# 감정 예측 - 6\n",
    "picks = [10212]\n",
    "predict = model.predict(padded_seqs[picks])\n",
    "predict_class = tf.math.argmax(predict, axis=1)\n",
    "print('감정 예측 점수 : ', predict)\n",
    "print(\"감정 예측 클래스 : \", predict_class.numpy())\n",
    "#argmax()를 이용해 분류 클래스들 중 예측 점수가 가장 큰 클래스 번호를 계산함\n",
    "# 즉 10212번째 문장이 어떤 감정 클래스에 포함되어 있는지 판단함\n",
    "#예측 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e464750dbb2f8340b2e9915e50c1e8c88c6015cc52b93a601b096fd1bd0da1cd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
